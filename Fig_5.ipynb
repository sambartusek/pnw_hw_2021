{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have the ERA5 data, wave analysis file, and model data collected in one directory and named as in All_figs_data_setup.ipynb, this notebook should be able to replicate Figure 5 in Bartusek et al., 2022.\n",
    "\n",
    "Sam Bartusek, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Data setup notebook (~15 min)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./All_figs_data_setup.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Climatology over all of june–july\n",
    "\n",
    "climspec = xr.open_mfdataset(glob.glob(path + 'ERA5*19812010clim*nh.nc'),combine='by_coords')\n",
    "climspec['t2m'] = climspec.t2m - 273.15\n",
    "climspec['t2mland'] = climspec.t2m.where(landmask>.5)\n",
    "climspec['skt'] = climspec.skt - 273.15\n",
    "climspec['sktland'] = climspec.skt.where(landmask>.5)\n",
    "climspec['z'] = climspec.z / 9.81\n",
    "climspec['swvl1'] = climspec.swvl1.where(landmask>.5)\n",
    "climspec['speed'] = (climspec.u**2 + climspec.v**2)**(1/2)\n",
    "climspec = climspec.drop('time_bnds')\n",
    "climspec\n",
    "climspec['time'] = (climspec.time.to_pandas() + pd.offsets.DateOffset(years=11)).values\n",
    "\n",
    "\n",
    "# Calculate daily-mean anomalies over all of June–July up to 2020\n",
    "\n",
    "test = rawto20[['sktland','swvl1','t2mland','z']].sel(time=(rawto20.time.dt.month == 6) | (rawto20.time.dt.month == 7))\n",
    "test.coords['time'] = test.time.dt.floor('1D')\n",
    "test = test.groupby('time').mean()\n",
    "month_day_str_raw = xr.DataArray(test.indexes['time'].strftime('%m-%d'), coords=test.time.coords)\n",
    "test['month_day_str'] = month_day_str_raw\n",
    "\n",
    "temp = climspec[['sktland','swvl1','t2mland','z']].sel(time=(climspec.time.dt.month == 6) | (climspec.time.dt.month == 7)).resample(time='1D').mean()\n",
    "month_day_str_clim = xr.DataArray(temp.indexes['time'].strftime('%m-%d'), coords=temp.time.coords)\n",
    "temp['month_day_str'] = month_day_str_clim\n",
    "anomsliceto20 = test.groupby('month_day_str') - temp.groupby('month_day_str').mean()\n",
    "\n",
    "\n",
    "# Take spatial mean over PNW\n",
    "\n",
    "with pbar:\n",
    "    anomsliceto20_pnw_mean = anomsliceto20.sel(latitude=pnwlat,longitude=pnwlon).weighted(weights).mean(('latitude','longitude')).compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select date range within June–July\n",
    "\n",
    "junelim = 1   #23-1  #1   (i.e., select days >= to this date)   (if calculating 3-day means for partial month specify one day outside the desired range)\n",
    "julylim = 31   #5+1  #31   (i.e., select days <= to this date)   (if calculating 3-day means for partial month specify one day outside the desired range)\n",
    "timeslice = slice(f'2021-06-{junelim}',f'2021-07-{julylim}') \n",
    "tt = ((anomsliceto20_pnw_mean.time.dt.month == 6) & (anomsliceto20_pnw_mean.time.dt.day >= junelim)) | ((anomsliceto20_pnw_mean.time.dt.month == 7) & (anomsliceto20_pnw_mean.time.dt.day <= julylim))\n",
    "\n",
    "\n",
    "# Select time-averaging window\n",
    "\n",
    "days = 1\n",
    "\n",
    "\n",
    "# Separate into historical periods\n",
    "\n",
    "qq79 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1979','1999')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq00 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('2000','2020')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq81 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1981','2010')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq91 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1991','2020')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq20 = anomsliceto20_pnw_mean.sel(time=tt).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq21 = anomdaily_pnw_mean.sel(time=timeslice).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq = xr.merge([qq20,qq21])\n",
    "eventlim = ((qq21.time.dt.month==6) & (qq21.time.dt.day>=23)) | ((qq21.time.dt.month==7) & (qq21.time.dt.day<=5))\n",
    "\n",
    "qq80 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1980','2000')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq81 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1981','2001')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq82 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1982','2002')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq83 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1983','2003')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq84 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1984','2004')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq85 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1985','2005')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq86 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1986','2006')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq87 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1987','2007')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq88 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1988','2008')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq89 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1989','2009')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq90 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1990','2010')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq91 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1991','2011')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq92 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1992','2012')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq93 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1993','2013')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq94 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1994','2014')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq95 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1995','2015')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq96 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1996','2016')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq97 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1997','2017')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq98 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1998','2018')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq99 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('1999','2019')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq05 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('2005','2020')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "qq10 = anomsliceto20_pnw_mean.sel(time=tt).sel(time=slice('2010','2020')).resample(time='1D').mean().rolling(time=days,center=True).mean().dropna('time')\n",
    "\n",
    "fac = len(qq20.sel(time='2020').time)\n",
    "\n",
    "\n",
    "# Fit skew normal distributions\n",
    "\n",
    "points = np.arange(-12,12.02,.02)\n",
    "# p21 = np.argwhere(np.round(points,3)>=np.round(qq21.t2mland.max().values,3))[0][0]\n",
    "p21 = np.argwhere(points>=qq21.t2mland.max().values)[0][0]\n",
    "\n",
    "fit79 = scipy.stats.skewnorm.fit(qq79.t2mland)\n",
    "pdf79 = scipy.stats.skewnorm.pdf(points, *fit79)\n",
    "sf79 = scipy.stats.skewnorm.sf(points, *fit79)\n",
    "\n",
    "fit81 = scipy.stats.skewnorm.fit(qq81.t2mland)\n",
    "pdf81 = scipy.stats.skewnorm.pdf(points, *fit81)\n",
    "sf81 = scipy.stats.skewnorm.sf(points, *fit81)\n",
    "\n",
    "fit91 = scipy.stats.skewnorm.fit(qq91.t2mland)\n",
    "pdf91 = scipy.stats.skewnorm.pdf(points, *fit91)\n",
    "sf91 = scipy.stats.skewnorm.sf(points, *fit91)\n",
    "\n",
    "fit00 = scipy.stats.skewnorm.fit(qq00.t2mland)\n",
    "pdf00 = scipy.stats.skewnorm.pdf(points, *fit00)\n",
    "sf00 = scipy.stats.skewnorm.sf(points, *fit00)\n",
    "\n",
    "fit21 = scipy.stats.skewnorm.fit(qq.t2mland)\n",
    "pdf21 = scipy.stats.skewnorm.pdf(points, *fit21)\n",
    "sf21 = scipy.stats.skewnorm.sf(points, *fit21)\n",
    "\n",
    "fit80 = scipy.stats.skewnorm.fit(qq80.t2mland)\n",
    "pdf80 = scipy.stats.skewnorm.pdf(points, *fit80)\n",
    "sf80 = scipy.stats.skewnorm.sf(points, *fit80)\n",
    "\n",
    "fit81 = scipy.stats.skewnorm.fit(qq81.t2mland)\n",
    "pdf81 = scipy.stats.skewnorm.pdf(points, *fit81)\n",
    "sf81 = scipy.stats.skewnorm.sf(points, *fit81)\n",
    "\n",
    "fit82 = scipy.stats.skewnorm.fit(qq82.t2mland)\n",
    "pdf82 = scipy.stats.skewnorm.pdf(points, *fit82)\n",
    "sf82 = scipy.stats.skewnorm.sf(points, *fit82)\n",
    "\n",
    "fit83 = scipy.stats.skewnorm.fit(qq83.t2mland)\n",
    "pdf83 = scipy.stats.skewnorm.pdf(points, *fit83)\n",
    "sf83 = scipy.stats.skewnorm.sf(points, *fit83)\n",
    "\n",
    "fit84 = scipy.stats.skewnorm.fit(qq84.t2mland)\n",
    "pdf84 = scipy.stats.skewnorm.pdf(points, *fit84)\n",
    "sf84 = scipy.stats.skewnorm.sf(points, *fit84)\n",
    "\n",
    "fit85 = scipy.stats.skewnorm.fit(qq85.t2mland)\n",
    "pdf85 = scipy.stats.skewnorm.pdf(points, *fit85)\n",
    "sf85 = scipy.stats.skewnorm.sf(points, *fit85)\n",
    "\n",
    "fit86 = scipy.stats.skewnorm.fit(qq86.t2mland)\n",
    "pdf86 = scipy.stats.skewnorm.pdf(points, *fit86)\n",
    "sf86 = scipy.stats.skewnorm.sf(points, *fit86)\n",
    "\n",
    "fit87 = scipy.stats.skewnorm.fit(qq87.t2mland)\n",
    "pdf87 = scipy.stats.skewnorm.pdf(points, *fit87)\n",
    "sf87 = scipy.stats.skewnorm.sf(points, *fit87)\n",
    "\n",
    "fit88 = scipy.stats.skewnorm.fit(qq88.t2mland)\n",
    "pdf88 = scipy.stats.skewnorm.pdf(points, *fit88)\n",
    "sf88 = scipy.stats.skewnorm.sf(points, *fit88)\n",
    "\n",
    "fit89 = scipy.stats.skewnorm.fit(qq89.t2mland)\n",
    "pdf89 = scipy.stats.skewnorm.pdf(points, *fit89)\n",
    "sf89 = scipy.stats.skewnorm.sf(points, *fit89)\n",
    "\n",
    "fit90 = scipy.stats.skewnorm.fit(qq90.t2mland)\n",
    "pdf90 = scipy.stats.skewnorm.pdf(points, *fit90)\n",
    "sf90 = scipy.stats.skewnorm.sf(points, *fit90)\n",
    "\n",
    "fit91 = scipy.stats.skewnorm.fit(qq91.t2mland)\n",
    "pdf91 = scipy.stats.skewnorm.pdf(points, *fit91)\n",
    "sf91 = scipy.stats.skewnorm.sf(points, *fit91)\n",
    "\n",
    "fit92 = scipy.stats.skewnorm.fit(qq92.t2mland)\n",
    "pdf92 = scipy.stats.skewnorm.pdf(points, *fit92)\n",
    "sf92 = scipy.stats.skewnorm.sf(points, *fit92)\n",
    "\n",
    "fit93 = scipy.stats.skewnorm.fit(qq93.t2mland)\n",
    "pdf93 = scipy.stats.skewnorm.pdf(points, *fit93)\n",
    "sf93 = scipy.stats.skewnorm.sf(points, *fit93)\n",
    "\n",
    "fit94 = scipy.stats.skewnorm.fit(qq94.t2mland)\n",
    "pdf94 = scipy.stats.skewnorm.pdf(points, *fit94)\n",
    "sf94 = scipy.stats.skewnorm.sf(points, *fit94)\n",
    "\n",
    "fit95 = scipy.stats.skewnorm.fit(qq95.t2mland)\n",
    "pdf95 = scipy.stats.skewnorm.pdf(points, *fit95)\n",
    "sf95 = scipy.stats.skewnorm.sf(points, *fit95)\n",
    "\n",
    "fit96 = scipy.stats.skewnorm.fit(qq96.t2mland)\n",
    "pdf96 = scipy.stats.skewnorm.pdf(points, *fit96)\n",
    "sf96 = scipy.stats.skewnorm.sf(points, *fit96)\n",
    "\n",
    "fit97 = scipy.stats.skewnorm.fit(qq97.t2mland)\n",
    "pdf97 = scipy.stats.skewnorm.pdf(points, *fit97)\n",
    "sf97 = scipy.stats.skewnorm.sf(points, *fit97)\n",
    "\n",
    "fit98 = scipy.stats.skewnorm.fit(qq98.t2mland)\n",
    "pdf98 = scipy.stats.skewnorm.pdf(points, *fit98)\n",
    "sf98 = scipy.stats.skewnorm.sf(points, *fit98)\n",
    "\n",
    "fit99 = scipy.stats.skewnorm.fit(qq99.t2mland)\n",
    "pdf99 = scipy.stats.skewnorm.pdf(points, *fit99)\n",
    "sf99 = scipy.stats.skewnorm.sf(points, *fit99)\n",
    "\n",
    "fit05 = scipy.stats.skewnorm.fit(qq05.t2mland)\n",
    "pdf05 = scipy.stats.skewnorm.pdf(points, *fit05)\n",
    "sf05 = scipy.stats.skewnorm.sf(points, *fit05)\n",
    "\n",
    "fit10 = scipy.stats.skewnorm.fit(qq10.t2mland)\n",
    "pdf10 = scipy.stats.skewnorm.pdf(points, *fit10)\n",
    "sf10 = scipy.stats.skewnorm.sf(points, *fit10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _5a)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "\n",
    "plt.figure(dpi=200,figsize=(4,4))\n",
    "plt.grid(c='.9',zorder=1)\n",
    "plt.axvline(0,c='.8')\n",
    "qq79.t2mland.plot.hist(bins=np.arange(np.min(points),np.max(points)+.75,.75),color='tab:blue',alpha=.12,histtype='bar',density=True,zorder=3)\n",
    "qq79.t2mland.plot.hist(bins=np.arange(np.min(points),np.max(points)+.75,.75),color='tab:blue',alpha=1,histtype='step',density=True,zorder=5)\n",
    "qq00.t2mland.plot.hist(bins=np.arange(np.min(points),np.max(points)+.75,.75),color='tab:red',alpha=.12,histtype='bar',density=True,zorder=3)\n",
    "qq00.t2mland.plot.hist(bins=np.arange(np.min(points),np.max(points)+.75,.75),color='tab:red',alpha=1,histtype='step',density=True,zorder=5)\n",
    "plt.plot(points,pdf79,color='tab:blue',alpha=1,label='1979–1999',zorder=301)\n",
    "plt.plot(points,pdf00,color='tab:red',alpha=1,label='2000–2020',zorder=301)\n",
    "plt.title('')\n",
    "\n",
    "xcoords = qq21.t2mland[qq21.t2mland<qq21.t2mland.max()].where(eventlim,drop=True)\n",
    "plt.axvline(x=xcoords[0],c='xkcd:dark red',lw=.75,ls='--',alpha=.3,zorder=1,label='2021 event')\n",
    "for xc in xcoords[1:]:\n",
    "    plt.axvline(x=xc,c='xkcd:dark red',lw=.75,ls='--',alpha=.3,zorder=1)\n",
    "plt.axvline(np.round(qq21.t2mland.max().values,2),c='xkcd:dark red',ls='--',label='2021 max',zorder=4)\n",
    "\n",
    "plt.legend(fontsize='small',loc='upper right').set_zorder(400)\n",
    "plt.xlim(-7,11)\n",
    "plt.title('June–July daily mean, skew normal fit',loc='left')\n",
    "plt.xlabel('Temperature anomaly [°C]')\n",
    "plt.ylabel('Probability density')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Calculate bootstraps:\n",
    "\n",
    "# reps = 1000  # 25 min?\n",
    "\n",
    "# n = len(qq79.t2mland)\n",
    "# xb79 = np.random.choice(qq79.t2mland, (n, reps))\n",
    "# n = len(qq81.t2mland)\n",
    "# xb81 = np.random.choice(qq81.t2mland, (n, reps))\n",
    "# n = len(qq91.t2mland)\n",
    "# xb91 = np.random.choice(qq91.t2mland, (n, reps))\n",
    "# n = len(qq00.t2mland)\n",
    "# xb00 = np.random.choice(qq00.t2mland, (n, reps))\n",
    "\n",
    "# sf79_b = np.zeros((len(points),reps))\n",
    "# sf81_b = np.zeros((len(points),reps))\n",
    "# sf91_b = np.zeros((len(points),reps))\n",
    "# sf00_b = np.zeros((len(points),reps))\n",
    "\n",
    "# for xx in range(reps):\n",
    "#     fit = scipy.stats.skewnorm.fit(xb79[:,xx])\n",
    "#     sf79_b[:,xx] = scipy.stats.skewnorm.sf(points, *fit)\n",
    "#     fit = scipy.stats.skewnorm.fit(xb00[:,xx])\n",
    "#     sf00_b[:,xx] = scipy.stats.skewnorm.sf(points, *fit)\n",
    "    \n",
    "#     if not xx % 100:\n",
    "#         print(xx)\n",
    "        \n",
    "# xr.DataArray(data = sf79_b, dims = ['points','reps'],coords = dict(points = ('points', points), reps = ('reps', np.arange(1,reps+1)) ) ).to_netcdf('sf79_b.nc')\n",
    "# xr.DataArray(data = sf00_b, dims = ['points','reps'],coords = dict(points = ('points', points), reps = ('reps', np.arange(1,reps+1)) ) ).to_netcdf('sf00_b.nc')\n",
    "\n",
    "\n",
    "# Open from .nc\n",
    "\n",
    "sf79_b = xr.open_dataarray('sf79_b.nc')\n",
    "sf00_b = xr.open_dataarray('sf00_b.nc')\n",
    "\n",
    "sf79_2p5,sf79_5,sf79_10,sf79_125,sf79_25,sf79_50,sf79_75,sf79_875,sf79_90,sf79_95,sf79_97p5 = np.percentile(sf79_b,[2.5,5,10,12.5,25,50,75,87.5,90,95,97.5],axis=1)\n",
    "sf00_2p5,sf00_5,sf00_10,sf00_125,sf00_25,sf00_50,sf00_75,sf00_875,sf00_90,sf00_95,sf00_97p5 = np.percentile(sf00_b,[2.5,5,10,12.5,25,50,75,87.5,90,95,97.5],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _5b)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fac = len(qq20.sel(time='2020').time)\n",
    "\n",
    "fig,ax = plt.subplots(1,1,dpi=150,figsize=(4,4))\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "ax.grid(c='.9',zorder=1)\n",
    "ax.plot(points,sf79*fac,color='tab:blue',lw=1.5,label='1979–1999',zorder=101)\n",
    "ax.fill_between(points,sf79_5*fac,sf79_95*fac,color='tab:blue',edgecolor='none',alpha=.12,zorder=101)\n",
    "ax.plot(points[p21],sf79[p21]*fac,color='tab:blue',ls='none',marker='o',label=f'~1/{int(round_to_n(1/sf79[p21]/fac,2)):,} yr',zorder=101)\n",
    "ax.plot(points,sf00*fac,color='tab:red',lw=1.5,label='2000–2020',zorder=101)\n",
    "ax.fill_between(points,sf00_5*fac,sf00_95*fac,color='tab:red',edgecolor='none',alpha=.12,zorder=101)\n",
    "ax.plot(points[p21],sf00[p21]*fac,color='tab:red',ls='none',marker='o',label=f'~1/{int(round_to_n(1/sf00[p21]/fac,2)):,} yr',zorder=101)\n",
    "\n",
    "ax.plot(points,sf79_5*fac,color='tab:blue',ls='--',lw=.8,alpha=.4,zorder=500)\n",
    "ax.plot(points,sf79_95*fac,color='tab:blue',ls='--',lw=.8,alpha=.4,zorder=500)\n",
    "ax.plot(points,sf00_5*fac,color='tab:red',ls='--',lw=.8,alpha=.4,zorder=500)\n",
    "ax.plot(points,sf00_95*fac,color='tab:red',ls='--',lw=.8,alpha=.4,zorder=500)\n",
    "\n",
    "xcoords = qq21.t2mland[qq21.t2mland<qq21.t2mland.max()].where(eventlim,drop=True)\n",
    "ax.axvline(x=xcoords[0],c='xkcd:dark red',lw=.75,ls='--',alpha=.3,label='2021 event',zorder=1)\n",
    "for xc in xcoords[1:]:\n",
    "    ax.axvline(x=xc,c='xkcd:dark red',lw=.75,ls='--',alpha=.3,zorder=1)\n",
    "ax.axvline(points[p21],c='xkcd:dark red',ls='--',label='2021 max',zorder=4)\n",
    "    \n",
    "ax.legend(fontsize='small',loc='lower left').set_zorder(500)\n",
    "ax.set_xlim(5,11.1)\n",
    "ax.set_ylim(1/(150000),1/(7.5))\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Temperature anomaly [°C]')\n",
    "ax.set_ylabel('Yearly probability of exceedence')\n",
    "\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax2.set_ylim((1/ymin),(1/ymax))\n",
    "ax2.set_yscale('log')\n",
    "ax2.plot([],[])\n",
    "# ax2.set_ylabel('Return period [years]')\n",
    "ax2.yaxis.set_major_formatter(mticker.FuncFormatter(lambda y, _: '{:,.16g}'.format(y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = [sf79[p21],\n",
    "         sf80[p21],\n",
    "         sf81[p21],\n",
    "         sf82[p21],\n",
    "         sf83[p21],\n",
    "         sf84[p21],\n",
    "         sf85[p21],\n",
    "         sf86[p21],\n",
    "         sf87[p21],\n",
    "         sf88[p21],\n",
    "         sf89[p21],\n",
    "         sf90[p21],\n",
    "         sf91[p21],\n",
    "         sf92[p21],\n",
    "         sf93[p21],\n",
    "         sf94[p21],\n",
    "         sf95[p21],\n",
    "         sf96[p21],\n",
    "         sf97[p21],\n",
    "         sf98[p21],\n",
    "         sf99[p21],\n",
    "         sf00[p21]]\n",
    "\n",
    "time = pd.date_range(\"1988-01-02\", freq=\"YS\", periods=22)\n",
    "pps = xr.Dataset({\"foo\": (\"time\", series), \"time\": time})\n",
    "pps = pps.foo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(1979,2081)\n",
    "\n",
    "x = pps.time.dt.year - 1989\n",
    "y = pps\n",
    "\n",
    "[a, b], res1 = scipy.optimize.curve_fit(lambda x1,a,b: a*np.exp(b*x1),  x,  y)\n",
    "y1 = a * np.exp(b * x)\n",
    "x2 = years - 1989\n",
    "y2 = a * np.exp(b * x2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _5c)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(4,2.5),dpi=150)\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "ax.plot(x + 1989, y1, color='0')\n",
    "\n",
    "ax.plot(1990,sf80[p21],marker='o',ls='none',color='xkcd:greyish purple',label='Probability of exceeding 2021 max')\n",
    "ax.plot(1989,sf79[p21],marker='o',ls='none',color='tab:blue',label='1979–1999')\n",
    "ax.plot(1991,sf81[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(1992,sf82[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(1993,sf83[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(1994,sf84[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(1995,sf85[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(1996,sf86[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(1997,sf87[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(1998,sf88[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(1999,sf89[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(2000,sf90[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(2001,sf91[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(2002,sf92[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(2003,sf93[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(2004,sf94[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(2005,sf95[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(2006,sf96[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(2007,sf97[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(2008,sf98[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(2009,sf99[p21],marker='o',ls='none',color='xkcd:greyish purple')\n",
    "ax.plot(2010,sf00[p21],marker='o',ls='none',color='tab:red',label='2000–2020')\n",
    "\n",
    "ax.set_ylim(0,1/200/fac)\n",
    "\n",
    "ax.set_ylabel('Probability of exceedance')\n",
    "ax.set_xlim(1988,2011)\n",
    "ax.grid(c='.9')\n",
    "ax.legend(fontsize='small',framealpha=.6,loc='upper left').set_zorder(2)\n",
    "\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax2.set_ylim((ymin*fac),(ymax*fac))\n",
    "ax2.set_ylabel('Return period [years]')\n",
    "ax2.set_yticks((1/200,1/400,1/1000,1/10000))\n",
    "ax2.set_yticklabels(('200','400','1,000','10,000'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detrend maxes\n",
    "\n",
    "data = qq20.t2mland.groupby('time.year').max().sel(year=slice('1979','2020')) \n",
    "data79 = qq20.t2mland.groupby('time.year').max().sel(year=slice('1979','1999')) \n",
    "data00 = qq20.t2mland.groupby('time.year').max().sel(year=slice('2000','2020')) \n",
    "data21 = qq21.t2mland.groupby('time.year').max()\n",
    "\n",
    "dataall = xr.concat([data,data21], dim='year')\n",
    "slope,intc,_,_,_ = scipy.stats.linregress(data.year,data)\n",
    "print(slope)\n",
    "print(intc + slope * 1979)\n",
    "hist_det = data - (data.year - data.year[0]) * slope\n",
    "qq79_det = hist_det.sel(year=slice('1979','1999'))\n",
    "qq81_det = hist_det.sel(year=slice('1981','2010'))\n",
    "qq91_det = hist_det.sel(year=slice('1991','2020'))\n",
    "qq00_det = hist_det.sel(year=slice('2000','2020'))\n",
    "curr_det = xr.concat([hist_det, data21 - (data21.year - data.year[0]) * slope], dim='year')\n",
    "\n",
    "dataallshift89 = curr_det + ((1989 - data.year[0]) * slope).values\n",
    "dataallshift10 = curr_det + ((2010 - data.year[0]) * slope).values\n",
    "dataallshift21 = curr_det + ((2021 - data.year[0]) * slope).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p21 = np.argwhere(points>=data21.values)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg = data.year.min().values\n",
    "print(beg)\n",
    "\n",
    "fithist = gev.fit(hist_det)\n",
    "print(fithist)\n",
    "fit = gev.fit(curr_det)\n",
    "print(fit)\n",
    "\n",
    "pdfhist = gev.pdf(points, *fithist)\n",
    "sfhist = gev.sf(points, *fithist)\n",
    "pdf = gev.pdf(points, *fit)\n",
    "sf = gev.sf(points, *fit)\n",
    "\n",
    "sfhist_all = np.zeros((len(points),len(years)))\n",
    "sf_all = np.zeros((len(points),len(years)))\n",
    "for ii,yy in enumerate(years):\n",
    "    sfhist_all[:,ii] = gev.sf(points, fithist[0], fithist[1] + (yy - beg) * slope, fithist[2])\n",
    "    sf_all[:,ii] = gev.sf(points, fit[0], fit[1] + (yy - beg) * slope, fit[2])\n",
    "\n",
    "sfhist79 = np.median(sfhist_all[:,1979-beg:1999-beg+1],1)\n",
    "sfhist81 = np.median(sfhist_all[:,1981-beg:2010-beg+1],1)\n",
    "sfhist91 = np.median(sfhist_all[:,1991-beg:2020-beg+1],1)\n",
    "sfhist00 = np.median(sfhist_all[:,2000-beg:2020-beg+1],1)\n",
    "sfhist21 = sfhist_all[:,2021-beg]\n",
    "sfhist30 = sfhist_all[:,2030-beg]\n",
    "sfhist40 = sfhist_all[:,2040-beg]\n",
    "sfhist50 = sfhist_all[:,2050-beg]\n",
    "sfhist60 = sfhist_all[:,2060-beg]\n",
    "sfhist70 = sfhist_all[:,2070-beg]\n",
    "sf8ist60 = sfhist_all[:,2080-beg]\n",
    "\n",
    "sf79 = np.median(sf_all[:,1979-beg:1999-beg+1],1)\n",
    "sf81 = np.median(sf_all[:,1981-beg:2010-beg+1],1)\n",
    "sf91 = np.median(sf_all[:,1991-beg:2020-beg+1],1)\n",
    "sf00 = np.median(sf_all[:,2000-beg:2020-beg+1],1)\n",
    "sf21 = sf_all[:,2021-beg]\n",
    "sf30 = sf_all[:,2030-beg]\n",
    "sf40 = sf_all[:,2040-beg]\n",
    "sf50 = sf_all[:,2050-beg]\n",
    "sf60 = sf_all[:,2060-beg]\n",
    "sf70 = sf_all[:,2070-beg]\n",
    "sf80 = sf_all[:,2080-beg]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### IGNORE ###\n",
    "\n",
    "# Bootstraps for including-2021\n",
    "\n",
    "# # Calculate bootstraps\n",
    "\n",
    "# reps = 10000  # ~1.5 min per thousand\n",
    "\n",
    "# n = len(curr_det.year)\n",
    "# xb = np.random.choice(curr_det, (n, reps))\n",
    "\n",
    "# sf_all_b = np.zeros((len(points),reps,len(curr_det.year)))\n",
    "# for xx in range(reps):\n",
    "#     fit_b = gev.fit(xb[:,xx])\n",
    "#     for ii,yy in enumerate(curr_det.year):\n",
    "#         sf_all_b[:,xx,ii] = gev.sf(points, fit_b[0], fit_b[1] + (yy - beg) * slope, fit_b[2])\n",
    "#     if not xx % 100:\n",
    "#         print(xx)\n",
    "\n",
    "# xr.DataArray(data = sf_all_b, dims = ['points','reps','years'],coords = dict(points = ('points', points), reps = ('reps', np.arange(1,reps+1)), years = ('years', curr_det.year.values) ) ).to_netcdf('sf_all_b.nc')\n",
    "\n",
    "\n",
    "# # Open from .nc\n",
    "\n",
    "# sf_all_b = xr.open_dataarray('sf_all_b.nc')\n",
    "# sf_all_5 = sf_all_b.quantile(.05,dim='reps')\n",
    "# sf_all_95 = sf_all_b.quantile(.95,dim='reps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### IGNORE ###\n",
    "\n",
    "# Bootstraps for excluding-2021\n",
    "\n",
    "# # Calculate bootstraps\n",
    "\n",
    "# reps = 10000  # ~1.5 min per thousand\n",
    "\n",
    "# n = len(hist_det.year)\n",
    "# xb = np.random.choice(hist_det, (n, reps))\n",
    "\n",
    "# sfhistall_b = np.zeros((len(points),reps,len(hist_det.year)))\n",
    "# for xx in range(reps):\n",
    "#     fit_b = gev.fit(xb[:,xx])\n",
    "#     for ii,yy in enumerate(hist_det.year):\n",
    "#         sfhistall_b[:,xx,ii] = gev.sf(points, fit_b[0], fit_b[1] + (yy - beg) * slope, fit_b[2])\n",
    "#     if not xx % 100:\n",
    "#         print(xx)\n",
    "\n",
    "# xr.DataArray(data = sfhistall_b, dims = ['points','reps','years'],coords = dict(points = ('points', points), reps = ('reps', np.arange(1,reps+1)), years = ('years', hist_det.year.values) ) ).to_netcdf('sfhistall_b.nc')\n",
    "\n",
    "\n",
    "# # Open from .nc\n",
    "\n",
    "# sfhistall_b = xr.open_dataarray('sfhistall_b.nc')\n",
    "# sfhistall_5 = sfhistall_b.quantile(.05,dim='reps')\n",
    "# sfhistall_95 = sfhistall_b.quantile(.95,dim='reps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open bootstrap percentiles\n",
    "\n",
    "sf_all_5 = xr.open_dataarray('sf_all_5.nc').values\n",
    "sf_all_95 = xr.open_dataarray('sf_all_95.nc').values\n",
    "sfhistall_5 = xr.open_dataarray('sfhistall_5.nc').values\n",
    "sfhistall_95 = xr.open_dataarray('sfhistall_95.nc').values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap intervals for historical periods\n",
    "\n",
    "sf79_5 = np.median(sf_all_5[:,1979-beg:1999-beg+1],1)\n",
    "sf81_5 = np.median(sf_all_5[:,1981-beg:2010-beg+1],1)\n",
    "sf91_5 = np.median(sf_all_5[:,1991-beg:2020-beg+1],1)\n",
    "sf00_5 = np.median(sf_all_5[:,2000-beg:2020-beg+1],1)\n",
    "sf21_5 = sf_all_5[:,2021-beg]\n",
    "sf79_95 = np.median(sf_all_95[:,1979-beg:1999-beg+1],1)\n",
    "sf81_95 = np.median(sf_all_95[:,1981-beg:2010-beg+1],1)\n",
    "sf91_95 = np.median(sf_all_95[:,1991-beg:2020-beg+1],1)\n",
    "sf00_95 = np.median(sf_all_95[:,2000-beg:2020-beg+1],1)\n",
    "sf21_95 = sf_all_95[:,2021-beg]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _5d)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,dpi=150,figsize=(4,4))#2.75))\n",
    "ax.grid(c='.9')\n",
    "\n",
    "ax.plot(curr_det.year, fit[1] + (curr_det.year - beg) * slope, color='xkcd:greyish purple', label='μ and 50-, 100-, and 1000-yr returns')\n",
    "ax.plot(curr_det.year, points[np.argmax((sf_all[:,:43]<1/50),axis=0)], color='xkcd:greyish purple')\n",
    "ax.fill_between(curr_det.year, points[np.argmax((sf_all_5[:,:43]<1/50),axis=0)], points[np.argmax((sf_all_95[:,:43]<1/50),axis=0)], color='xkcd:greyish purple', edgecolor='none', alpha=.2, zorder=2)\n",
    "ax.plot(curr_det.year, points[np.argmax((sf_all[:,:43]<1/100),axis=0)], color='xkcd:greyish purple')\n",
    "ax.plot(curr_det.year, points[np.argmax((sf_all[:,:43]<1/1000),axis=0)], color='xkcd:greyish purple')\n",
    "\n",
    "ax.plot(curr_det.year, fithist[1] + (curr_det.year - beg) * slope, color='.5', alpha=.4, ls='--', label='Fit excluding 2021')\n",
    "ax.plot(curr_det.year, points[np.argmax((sfhist_all[:,:43]<1/50),axis=0)], color='.5', alpha=.4, ls='--')\n",
    "ax.fill_between(hist_det.year, points[np.argmax((sfhistall_5[:,:43]<1/50),axis=0)], points[np.argmax((sfhistall_95[:,:43]<1/50),axis=0)], color='.5', edgecolor='none', alpha=.2, zorder=2)\n",
    "ax.plot(curr_det.year, points[np.argmax((sfhist_all[:,:43]<1/100),axis=0)], color='.5', alpha=.4, ls='--')\n",
    "ax.plot(curr_det.year, points[np.argmax((sfhist_all[:,:43]<1/1000),axis=0)], color='.5', alpha=.4, ls='--')\n",
    "\n",
    "ax.plot(dataall.year, dataall, color='0', lw=1, marker='.', markersize=4)\n",
    "ax.plot(data21.year, data21, marker='d', ls='none', color='xkcd:dark red', label='2021 max')\n",
    "\n",
    "ax.legend(fontsize='small',loc='upper left',frameon=True,framealpha=.6)\n",
    "ax.set_xlim(beg-1,2022)\n",
    "ax.set_ylabel('Temperature anomaly [°C]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _5e)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,dpi=150,figsize=(4,4))\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "ax.grid(c='.9',zorder=1)\n",
    "\n",
    "# curr:\n",
    "\n",
    "ax.plot(points,sf79,color='tab:blue',lw=1.5,label='1979–1999',zorder=101)\n",
    "ax.fill_between(points,sf79_5,sf79_95,color='tab:blue',edgecolor='none',alpha=.12,zorder=101)\n",
    "ax.plot(points[p21],sf79[p21],color='tab:blue',ls='none',marker='o',label=f'~1/{int(round_to_n(1/sf79[p21],2)):,} yr',zorder=101)\n",
    "ax.plot(points,sf00,color='tab:red',lw=1.5,label='2000–2020',zorder=101)\n",
    "ax.fill_between(points,sf00_5,sf00_95,color='tab:red',edgecolor='none',alpha=.12,zorder=101)\n",
    "ax.plot(points[p21],sf00[p21],color='tab:red',ls='none',marker='o',label=f'~1/{int(round_to_n(1/sf00[p21],1)):,} yr',zorder=101)\n",
    "ax.plot(points,sf21,color='xkcd:dark red',lw=1.5,label='2021')\n",
    "ax.plot(points[p21],sf21[p21],color='xkcd:dark red',ls='none',marker='o',label=f'~1/{int(round_to_n(1/sf21[p21],1)):,} yr',zorder=101)\n",
    "ax.plot(points,sf40,color='tab:pink',lw=2,ls=':',label='2040')\n",
    "ax.plot(points[p21],sf40[p21],color='tab:pink',ls='none',marker='o',zorder=101)\n",
    "ax.plot(points,sf60,color='xkcd:light rose',lw=2,ls=':',label='2060')\n",
    "ax.plot(points[p21],sf60[p21],color='xkcd:light rose',ls='none',marker='o',zorder=101)\n",
    "\n",
    "\n",
    "# hist:\n",
    "\n",
    "ax.plot(points,sfhist79,color='.5',lw=1.5,ls='--',alpha=.4,zorder=2)\n",
    "ax.plot(points,sfhist00,color='.5',lw=1.5,ls='--',alpha=.4,zorder=2)\n",
    "ax.plot(points,sfhist21,color='.5',lw=1.5,ls='--',alpha=.4,zorder=2)\n",
    "\n",
    "ax.plot(points,sf79_5,color='tab:blue',ls='--',lw=.7,alpha=.5,zorder=500)\n",
    "ax.plot(points,sf79_95,color='tab:blue',ls='--',lw=.7,alpha=.5,zorder=500)\n",
    "ax.plot(points,sf00_5,color='tab:red',ls='--',lw=.7,alpha=.5,zorder=500)\n",
    "ax.plot(points,sf00_95,color='tab:red',ls='--',lw=.7,alpha=.5,zorder=500)\n",
    "\n",
    "ax.plot([],[],color='.5',lw=1.5,ls='--',alpha=.4,label='Fit excluding 2021')\n",
    "ax.axvline(points[p21],c='xkcd:dark red',ls='--',label='2021 max',zorder=4)\n",
    "\n",
    "ax.legend(fontsize='small',loc='lower left',framealpha=.6).set_zorder(501)\n",
    "ax.set_xlim(5,11.1)\n",
    "ax.set_ylim(1/(150000),1/(7.5))\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Temperature anomaly [°C]')\n",
    "ax.set_ylabel('Yearly probability of exceedence')\n",
    "\n",
    "ax.axhline(1e-1,c='.9',zorder=1)\n",
    "ax.axhline(1e-2,c='.9',zorder=1)\n",
    "ax.axhline(1e-3,c='.9',zorder=1)\n",
    "ax.axhline(1e-4,c='.9',zorder=1)\n",
    "ax.axhline(1e-5,c='.9',zorder=1)\n",
    "\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax2.set_ylim((1/ymin),(1/ymax))\n",
    "ax2.set_yscale('log')\n",
    "ax2.plot([],[])\n",
    "ax2.set_ylabel('Return period [years]')\n",
    "ax2.yaxis.set_major_formatter(mticker.FuncFormatter(lambda y, _: '{:,.16g}'.format(y)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _5f)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(4,2.5),dpi=150)\n",
    "ax2 = ax.twinx()\n",
    "ax.plot(years, sf_all[p21,:],color='xkcd:greyish purple', label='Probability of exceeding 2021 max')\n",
    "ax.plot(years, sfhist_all[p21,:],ls='--',lw=2,color='.5',alpha=.4, label='Fit excluding 2021')\n",
    "ax.plot(1989,sf79[p21],marker='o',ls='none',color='tab:blue')\n",
    "ax.plot(2010,sf00[p21],marker='o',ls='none',color='tab:red')\n",
    "ax.plot(2021,sf21[p21],marker='o',ls='none',color='xkcd:dark red')\n",
    "ax.plot(2040,sf40[p21],marker='o',ls='none',color='tab:pink')\n",
    "ax.plot(2060,sf60[p21],marker='o',ls='none',color='xkcd:light rose')\n",
    "ax.set_ylabel('Probability of exceedance')\n",
    "ax.set_xlim(1979,2080)\n",
    "ax.grid(c='.9')\n",
    "ax.set_ylim(0,1/8)\n",
    "ax.legend(fontsize='small',framealpha=.6)\n",
    "\n",
    "ymin, ymax = ax.get_ylim()\n",
    "ax2.set_ylim((ymin),(ymax))\n",
    "ax2.set_ylabel('Return period [years]')\n",
    "ax2.set_yticks((1/8,1/10,1/20,1/100,1/1000))\n",
    "ax2.set_yticklabels(('8','10','20','100','1,000'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
